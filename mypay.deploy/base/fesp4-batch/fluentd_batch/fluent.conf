# defines the source of the log file
<source>
  @type tail
  path /var/log/batch/*.log
  pos_file /var/log/batch/access_log.pos
      <parse>
        @type multiline_grok
        grok_failure_key grokfailure
        multiline_start_regexp /^\d{4}-\d{1,2}-\d{1,2} \d{1,2}:\d{1,2}:\d{1,2}/
        <grok>
          pattern (?<timestamp>%{YEAR}-%{MONTHNUM}-%{MONTHDAY} %{NUMBER}:%{NUMBER}:%{NUMBER}) %{WORD:level} %{GREEDYDATA:message} 
        </grok>
        <grok>
          pattern Eseguito caricamento file:%{GREEDYDATA:file_imported}
         </grok>
        <grok>
          pattern message%{GREEDYDATA:message}
         </grok>
      </parse>
  read_from_head true
  tag "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX']}"
</source>

<filter **>
        @type record_transformer
		enable_ruby true
        <record>
        hostname ${hostname}
        </record>
</filter>
# Ship data to Elasticsearch
<match "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX']}">
  @type copy
  <store>
    @type elasticsearch
    include_tag_key true
    host "#{ENV['FLUENT_ELASTICSEARCH_HOST']}"
    port "#{ENV['FLUENT_ELASTICSEARCH_PORT']}"
    scheme "#{ENV['FLUENT_ELASTICSEARCH_SCHEME'] || 'https'}"
    ssl_verify "#{ENV['FLUENT_ELASTICSEARCH_SSL_VERIFY'] || 'false'}"
    ssl_version "#{ENV['FLUENT_ELASTICSEARCH_SSL_VERSION'] || 'TLSv1_2'}"
    user "#{ENV['FLUENT_ELASTICSEARCH_USER']}"
    password "#{ENV['FLUENT_ELASTICSEARCH_PASSWORD']}"
    logstash_format "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_FORMAT'] || 'true'}"
    logstash_prefix "#{ENV['FLUENT_ELASTICSEARCH_LOGSTASH_PREFIX'] || 'mypay4_backend.access'}"
    flush_interval 10s
    # Disable the limit on the number of retries (retry forever).
    disable_retry_limit true
  </store>
</match>
